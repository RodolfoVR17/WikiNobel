{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import wikipedia\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def convert_encoding(element):\n",
    "    if isinstance(element, str):\n",
    "        return element.encode('ISO-8859-1').decode('UTF-8')\n",
    "    else:\n",
    "        return element\n",
    "\n",
    "def scrape_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    rows = table.find_all('tr')\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [col.text.strip() for col in cols]\n",
    "        data.append(cols)\n",
    "    return data\n",
    "\n",
    "\n",
    "def clean_dataframe(df):\n",
    "\n",
    "    # Load the data with specified encoding\n",
    "    df = pd.read_csv('nobel.csv', encoding='ISO-8859-1')\n",
    "\n",
    "    # Remove whitespaces\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    # Handle missing values (this will depend on your specific data)\n",
    "    df = df.dropna()  # This line removes any rows with missing values\n",
    "\n",
    "    # Convert data to appropriate types\n",
    "    df['year'] = pd.to_datetime(df['year'], format='%Y', errors='coerce')\n",
    "\n",
    "    df = df.applymap(convert_encoding)\n",
    "    df = df.dropna(how='any')\n",
    "    display(df)\n",
    "\n",
    "    display(df.head())\n",
    "    df = pd.read_csv('nobel.csv').dropna(how='all')\n",
    "    df = df.fillna('No award')\n",
    "\n",
    "\n",
    "    df.to_csv(\"nobel.csv\", index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_Nobel_laureates'\n",
    "\n",
    "\n",
    "df = pd.DataFrame(scrape_data(url), columns=['Year', 'Physics', 'Chemistry', 'Medicine', 'Literature', 'Peace', 'Economics'])\n",
    "\n",
    "df = clean_dataframe(df)\n",
    "\n",
    "\n",
    "def look_year_and_category(year, category):\n",
    "    df_year = df[(df['year'] == year)]\n",
    "    word_list = df_year[category].tolist()\n",
    "    word_list = (word_list[0].split(';'))\n",
    "    return word_list\n",
    "\n",
    "\n",
    "print(look_year_and_category(1998, 'economics'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_column_with_name(df, name):\n",
    "    # Convert all columns to string and apply the mask\n",
    "    mask = df.applymap(str).apply(lambda col: col.str.contains(name, na=False))\n",
    "    \n",
    "    # Find columns where 'name' is found\n",
    "    columns_with_name = df.columns[mask.any(axis=0)]\n",
    "    \n",
    "    # Return the column names as a list\n",
    "    return list(columns_with_name)\n",
    "\n",
    "print(find_column_with_name(df, 'Marie Curie'))\n",
    "\n",
    "\n",
    "wikipedia.set_lang(\"en\")  # For Spanish, for example\n",
    "\n",
    "\n",
    "# Search for pages\n",
    "results = wikipedia.search(\"Nobel Prize\")\n",
    "\n",
    "# Access a specific page\n",
    "page = wikipedia.page(\"List of Nobel laureates by country\")\n",
    "\n",
    "# Get the whole page content\n",
    "content = page.content\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    page = wikipedia.page(\"List of Nobel laureates by country\")\n",
    "    content = page.content\n",
    "    contentList = content.split(\"===\")\n",
    "    your_string = \"This is the string you want to save as a text file.\"\n",
    "\n",
    "    # Specify the filename\n",
    "    filename = \"country.txt\"\n",
    "\n",
    "    \n",
    "\n",
    "    # Writing the string to the text file\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "    print(f\"Content saved to {filename}\")\n",
    "\n",
    "except wikipedia.exceptions.PageError:\n",
    "    print(\"Page not found\")\n",
    "except wikipedia.exceptions.DisambiguationError as e:\n",
    "    print(\"Disambiguation error. Possible options include:\")\n",
    "    print(e.options)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"United States\"\n",
    "contentListCountry = contentList\n",
    "\n",
    "def set_countries_to_list(): \n",
    "    \n",
    "    for i, content in enumerate(contentListCountry):\n",
    "        if i % 2 != 0:  # If the index is uneven\n",
    "            contentListCountry[i] = content.strip()  # Remove spaces at the beginning and end\n",
    "            #print(contentListCountry[i])\n",
    "\n",
    "    return contentListCountry\n",
    "\n",
    "set_countries_to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_people_by_country(country):\n",
    "    if country in contentListCountry:\n",
    "        foundindex = contentListCountry.index(country)\n",
    "        \n",
    "        #print(contentList[foundindex+1])\n",
    "        return contentList[foundindex+1]\n",
    "    else:\n",
    "        print(\"Country not found\")\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_de_personas = give_me_people_by_country(\"Canada\")\n",
    "print(lista_de_personas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def filterable(data_string):\n",
    "    # The string containing the data\n",
    "    data_string \n",
    "\n",
    "    # Remove parentheses and split the string into lines\n",
    "    data_string = data_string.strip(\"()\")\n",
    "    lines = data_string.split('\\n')\n",
    "\n",
    "    # Parse each line and collect data\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        # Splitting each line by comma and stripping extra whitespace\n",
    "        parts = [part.strip() for part in line.split(',')]\n",
    "        if len(parts) == 3:  # Making sure the line is properly formatted\n",
    "            data.append(parts)\n",
    "\n",
    "    # Creating a DataFrame\n",
    "    df = pd.DataFrame(data, columns=['Name', 'Prize', 'Year'])\n",
    "\n",
    "    #display(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_final(country, category):\n",
    "    lista_de_personas = give_me_people_by_country(country)\n",
    "    df = filterable(lista_de_personas)\n",
    "    df_category = df[df['Prize'] == category]\n",
    "\n",
    "    if df_category.empty:\n",
    "        print(f'No awards for {country} in {category}')\n",
    "    else:\n",
    "        display(df_category[['Name','Prize']])\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_final(\"Canada\", \"Economics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_final(\"Mexico\", \"Economics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_final(\"Mexico\", \"Physics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_final(\"Mexico\", \"Chemistry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_final(\"United States\", \"Physics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wiki_nobel():\n",
    "    category_dropdown = widgets.Dropdown(\n",
    "        options=['Physics', 'Chemistry', 'Medicine', 'Literature', 'Peace', 'Economics'],\n",
    "        \n",
    "        description='Category:',\n",
    "        disabled=False,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    countries_list = set_countries_to_list()\n",
    "    list_of_countries = []\n",
    "\n",
    "    for i, content in enumerate(countries_list):\n",
    "            if i % 2 != 0:  # If the index is uneven\n",
    "                contentListCountry[i] = content.strip()  # Remove spaces at the beginning and end\n",
    "                list_of_countries.append(contentListCountry[i])\n",
    "\n",
    "\n",
    "    country_dropwdown = widgets.Dropdown(\n",
    "        options=list_of_countries,\n",
    "        \n",
    "        description='Country:',\n",
    "        disabled=False,\n",
    "    )\n",
    "\n",
    "    button = widgets.Button(description='Search Nobel!')\n",
    "\n",
    "    display(category_dropdown,country_dropwdown,button)\n",
    "\n",
    "    def on_button_clicked(b): \n",
    "        print (\"Searching...\")\n",
    "        clear_output()\n",
    "        display(category_dropdown,country_dropwdown,button)\n",
    "        response = find_final(country_dropwdown.value, category_dropdown.value)\n",
    "        \n",
    "\n",
    "    button.on_click(on_button_clicked)\n",
    "\n",
    "    #pd.set_option(display.max_rows, 200)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_nobel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
